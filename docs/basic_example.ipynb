{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dce36b5-c302-4bc5-b20e-d04eaf5aa49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "ROOT_PATH = str('../sfs')\n",
    "sys.path.append(ROOT_PATH)\n",
    "from shapwise_feature_selector import *\n",
    "np.random.seed(0)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "481c3a22-8840-4311-abb7-59eaa0f6f59a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_0</th>\n",
       "      <th>num_1</th>\n",
       "      <th>num_2</th>\n",
       "      <th>num_3</th>\n",
       "      <th>num_4</th>\n",
       "      <th>num_5</th>\n",
       "      <th>num_6</th>\n",
       "      <th>num_7</th>\n",
       "      <th>num_8</th>\n",
       "      <th>num_9</th>\n",
       "      <th>...</th>\n",
       "      <th>cat_191</th>\n",
       "      <th>cat_192</th>\n",
       "      <th>cat_193</th>\n",
       "      <th>cat_194</th>\n",
       "      <th>cat_195</th>\n",
       "      <th>cat_196</th>\n",
       "      <th>cat_197</th>\n",
       "      <th>cat_198</th>\n",
       "      <th>cat_199</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.764052</td>\n",
       "      <td>0.400157</td>\n",
       "      <td>0.978738</td>\n",
       "      <td>2.240893</td>\n",
       "      <td>1.867558</td>\n",
       "      <td>-0.977278</td>\n",
       "      <td>0.950088</td>\n",
       "      <td>-0.151357</td>\n",
       "      <td>-0.103219</td>\n",
       "      <td>0.410599</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.411172</td>\n",
       "      <td>0.785804</td>\n",
       "      <td>-0.057470</td>\n",
       "      <td>-0.391217</td>\n",
       "      <td>0.940918</td>\n",
       "      <td>0.405204</td>\n",
       "      <td>0.498052</td>\n",
       "      <td>-0.026192</td>\n",
       "      <td>-1.688230</td>\n",
       "      <td>-0.112466</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.430771</td>\n",
       "      <td>-0.149892</td>\n",
       "      <td>-1.006037</td>\n",
       "      <td>-0.821550</td>\n",
       "      <td>-1.548254</td>\n",
       "      <td>0.531975</td>\n",
       "      <td>1.260569</td>\n",
       "      <td>-0.100394</td>\n",
       "      <td>-0.400349</td>\n",
       "      <td>-1.472323</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.152177</td>\n",
       "      <td>-0.374126</td>\n",
       "      <td>-0.013451</td>\n",
       "      <td>0.815472</td>\n",
       "      <td>0.410602</td>\n",
       "      <td>0.480970</td>\n",
       "      <td>-0.635430</td>\n",
       "      <td>0.852830</td>\n",
       "      <td>0.669562</td>\n",
       "      <td>1.004419</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.333342</td>\n",
       "      <td>0.367784</td>\n",
       "      <td>-1.388233</td>\n",
       "      <td>-2.575203</td>\n",
       "      <td>-0.836106</td>\n",
       "      <td>0.331092</td>\n",
       "      <td>-0.269881</td>\n",
       "      <td>1.267131</td>\n",
       "      <td>0.183753</td>\n",
       "      <td>-0.766310</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      num_0     num_1     num_2     num_3     num_4     num_5     num_6  \\\n",
       "0  1.764052  0.400157  0.978738  2.240893  1.867558 -0.977278  0.950088   \n",
       "1  1.411172  0.785804 -0.057470 -0.391217  0.940918  0.405204  0.498052   \n",
       "2  0.430771 -0.149892 -1.006037 -0.821550 -1.548254  0.531975  1.260569   \n",
       "3  0.152177 -0.374126 -0.013451  0.815472  0.410602  0.480970 -0.635430   \n",
       "4 -1.333342  0.367784 -1.388233 -2.575203 -0.836106  0.331092 -0.269881   \n",
       "\n",
       "      num_7     num_8     num_9  ...  cat_191  cat_192  cat_193  cat_194  \\\n",
       "0 -0.151357 -0.103219  0.410599  ...        2        2        1        2   \n",
       "1 -0.026192 -1.688230 -0.112466  ...        2        0        2        0   \n",
       "2 -0.100394 -0.400349 -1.472323  ...        1        0        2        2   \n",
       "3  0.852830  0.669562  1.004419  ...        0        0        1        0   \n",
       "4  1.267131  0.183753 -0.766310  ...        2        0        2        1   \n",
       "\n",
       "   cat_195  cat_196  cat_197  cat_198  cat_199  target  \n",
       "0        0        2        1        2        0       1  \n",
       "1        2        2        1        1        1       0  \n",
       "2        0        1        1        2        2       0  \n",
       "3        2        0        2        0        1       0  \n",
       "4        1        0        1        2        0       1  \n",
       "\n",
       "[5 rows x 1001 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from category_encoders import OneHotEncoder\n",
    "\n",
    "def generate_data(n_samples=2500, n_features=1000, n_categorical_features=200):\n",
    "    \"\"\"\n",
    "    Generate synthetic numerical and categorical data.\n",
    "    \"\"\"\n",
    "    n_numerical_features = n_features - n_categorical_features\n",
    "    numerical_data = np.random.randn(n_samples, n_numerical_features)\n",
    "    categorical_data = np.random.randint(0, 3, size=(n_samples, n_categorical_features))\n",
    "    # Explicitly name all columns\n",
    "    numerical_columns = [f'num_{i}' for i in range(n_numerical_features)]\n",
    "    categorical_columns = [f'cat_{i}' for i in range(n_categorical_features)]\n",
    "    df_numerical = pd.DataFrame(numerical_data, columns=numerical_columns)\n",
    "    df_categorical = pd.DataFrame(categorical_data, columns=categorical_columns)\n",
    "    df = pd.concat([df_numerical, df_categorical], axis=1)\n",
    "    return df\n",
    "\n",
    "def introduce_signal(df, n_numerical_features, signal_strength=0.8, train_only_signal=False, train_size=0.8):\n",
    "    \"\"\"\n",
    "    Introduce a signal into the data.\n",
    "    \"\"\"\n",
    "    n_samples = len(df)\n",
    "    numerical_columns = [f'num_{i}' for i in range(n_numerical_features)]\n",
    "    signal_features = np.random.choice(numerical_columns, size=10, replace=False)  # 10 numerical features contribute to the signal\n",
    "    noise = np.random.randn(n_samples) * (1 - signal_strength)\n",
    "    target = np.dot(df[signal_features].values, np.random.rand(len(signal_features))) + noise\n",
    "    df['target'] = (target > np.median(target)).astype(int)  # Binary classification\n",
    "    \n",
    "    if train_only_signal:\n",
    "        n_train = int(n_samples * train_size)\n",
    "        train_indices = np.random.choice(range(n_samples), size=n_train, replace=False)\n",
    "        test_indices = list(set(range(n_samples)) - set(train_indices))\n",
    "        # Zeroing out signal in test set for specific signal features\n",
    "        for feature in signal_features:\n",
    "            df.loc[test_indices, feature] = np.random.randn(len(test_indices))\n",
    "            \n",
    "    return df, signal_features\n",
    "\n",
    "def process_data(df, target_column='target'):\n",
    "    \"\"\"\n",
    "    One-hot encode categorical variables and split the data into train and test sets.\n",
    "    \"\"\"\n",
    "    encoder = OneHotEncoder(cols=[col for col in df.columns if 'cat' in col], use_cat_names=True)\n",
    "    df_encoded = encoder.fit_transform(df.drop(target_column, axis=1))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_encoded, df[target_column], test_size=0.2, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "n_features = 1000\n",
    "n_categorical_features = 200\n",
    "n_numerical_features = n_features - n_categorical_features\n",
    "\n",
    "df = generate_data(n_samples=2500, n_features=n_features, n_categorical_features=n_categorical_features)\n",
    "df, signal_features = introduce_signal(df, n_numerical_features, train_only_signal=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d846349-e954-46a9-b7ca-bee730d92e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_0</th>\n",
       "      <th>num_1</th>\n",
       "      <th>num_2</th>\n",
       "      <th>num_3</th>\n",
       "      <th>num_4</th>\n",
       "      <th>num_5</th>\n",
       "      <th>num_6</th>\n",
       "      <th>num_7</th>\n",
       "      <th>num_8</th>\n",
       "      <th>num_9</th>\n",
       "      <th>...</th>\n",
       "      <th>cat_196_0.0</th>\n",
       "      <th>cat_197_1.0</th>\n",
       "      <th>cat_197_2.0</th>\n",
       "      <th>cat_197_0.0</th>\n",
       "      <th>cat_198_2.0</th>\n",
       "      <th>cat_198_1.0</th>\n",
       "      <th>cat_198_0.0</th>\n",
       "      <th>cat_199_0.0</th>\n",
       "      <th>cat_199_1.0</th>\n",
       "      <th>cat_199_2.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2055</th>\n",
       "      <td>-0.267790</td>\n",
       "      <td>-1.244953</td>\n",
       "      <td>0.579719</td>\n",
       "      <td>0.532729</td>\n",
       "      <td>-1.599408</td>\n",
       "      <td>0.273115</td>\n",
       "      <td>1.508266</td>\n",
       "      <td>-1.544335</td>\n",
       "      <td>1.192402</td>\n",
       "      <td>-2.245811</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961</th>\n",
       "      <td>0.291132</td>\n",
       "      <td>0.354325</td>\n",
       "      <td>-1.435145</td>\n",
       "      <td>-2.008045</td>\n",
       "      <td>-0.841351</td>\n",
       "      <td>-1.078707</td>\n",
       "      <td>-0.368103</td>\n",
       "      <td>-0.297344</td>\n",
       "      <td>-0.370908</td>\n",
       "      <td>0.778764</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>1.284703</td>\n",
       "      <td>-0.129104</td>\n",
       "      <td>-1.632991</td>\n",
       "      <td>0.518368</td>\n",
       "      <td>-0.341115</td>\n",
       "      <td>-0.809103</td>\n",
       "      <td>-0.423381</td>\n",
       "      <td>-0.630384</td>\n",
       "      <td>-0.808723</td>\n",
       "      <td>1.136608</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2326</th>\n",
       "      <td>0.306530</td>\n",
       "      <td>1.119647</td>\n",
       "      <td>2.299225</td>\n",
       "      <td>-1.237770</td>\n",
       "      <td>1.204511</td>\n",
       "      <td>0.795546</td>\n",
       "      <td>1.779258</td>\n",
       "      <td>1.133944</td>\n",
       "      <td>-0.389372</td>\n",
       "      <td>0.915985</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>0.585654</td>\n",
       "      <td>-1.942345</td>\n",
       "      <td>-0.842600</td>\n",
       "      <td>0.420766</td>\n",
       "      <td>0.975450</td>\n",
       "      <td>-0.769837</td>\n",
       "      <td>0.898704</td>\n",
       "      <td>0.222523</td>\n",
       "      <td>-0.419532</td>\n",
       "      <td>0.453049</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1400 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         num_0     num_1     num_2     num_3     num_4     num_5     num_6  \\\n",
       "2055 -0.267790 -1.244953  0.579719  0.532729 -1.599408  0.273115  1.508266   \n",
       "1961  0.291132  0.354325 -1.435145 -2.008045 -0.841351 -1.078707 -0.368103   \n",
       "1864  1.284703 -0.129104 -1.632991  0.518368 -0.341115 -0.809103 -0.423381   \n",
       "2326  0.306530  1.119647  2.299225 -1.237770  1.204511  0.795546  1.779258   \n",
       "461   0.585654 -1.942345 -0.842600  0.420766  0.975450 -0.769837  0.898704   \n",
       "\n",
       "         num_7     num_8     num_9  ...  cat_196_0.0  cat_197_1.0  \\\n",
       "2055 -1.544335  1.192402 -2.245811  ...            0            0   \n",
       "1961 -0.297344 -0.370908  0.778764  ...            0            0   \n",
       "1864 -0.630384 -0.808723  1.136608  ...            0            0   \n",
       "2326  1.133944 -0.389372  0.915985  ...            0            0   \n",
       "461   0.222523 -0.419532  0.453049  ...            0            0   \n",
       "\n",
       "      cat_197_2.0  cat_197_0.0  cat_198_2.0  cat_198_1.0  cat_198_0.0  \\\n",
       "2055            0            1            0            0            1   \n",
       "1961            1            0            1            0            0   \n",
       "1864            1            0            1            0            0   \n",
       "2326            1            0            1            0            0   \n",
       "461             1            0            1            0            0   \n",
       "\n",
       "      cat_199_0.0  cat_199_1.0  cat_199_2.0  \n",
       "2055            1            0            0  \n",
       "1961            0            1            0  \n",
       "1864            1            0            0  \n",
       "2326            1            0            0  \n",
       "461             0            1            0  \n",
       "\n",
       "[5 rows x 1400 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = process_data(df)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ef898d2-85de-4f9d-b74a-e0afd65ce19c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.68\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "800775d8-33b2-4e47-a28c-fb0e4890af31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sfs_model = SHAPwiseFeatureSelector(clf, accuracy_score, number_top_fi = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56583ccd-6356-4be9-960b-8c1d299448aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noisy feature detected: num_388 original_score (with num_388): 0.678, new score (without num_388): 0.678\n",
      "Noisy feature detected: num_262 original_score (with num_262): 0.678, new score (without num_262): 0.686\n",
      "Noisy feature detected: num_277 original_score (with num_277): 0.686, new score (without num_277): 0.694\n",
      "Noisy feature detected: num_609 original_score (with num_609): 0.694, new score (without num_609): 0.696\n",
      "Noisy feature detected: num_477 original_score (with num_477): 0.696, new score (without num_477): 0.7\n",
      "Noisy feature detected: num_395 original_score (with num_395): 0.7, new score (without num_395): 0.718\n",
      "Summary:\n",
      "Before drop: 0.678% After drop: 0.718%\n",
      "Improvement of 5.9%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SHAPwiseFeatureSelector(base_estimator=RandomForestClassifier(random_state=42),\n",
       "                        metric=&lt;function accuracy_score at 0x7f8c6a91ff70&gt;,\n",
       "                        number_top_fi=50)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SHAPwiseFeatureSelector</label><div class=\"sk-toggleable__content\"><pre>SHAPwiseFeatureSelector(base_estimator=RandomForestClassifier(random_state=42),\n",
       "                        metric=&lt;function accuracy_score at 0x7f8c6a91ff70&gt;,\n",
       "                        number_top_fi=50)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">base_estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "SHAPwiseFeatureSelector(base_estimator=RandomForestClassifier(random_state=42),\n",
       "                        metric=<function accuracy_score at 0x7f8c6a91ff70>,\n",
       "                        number_top_fi=50)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfs_model.fit(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa14a7d8-0638-4257-b024-68ac8c5adfd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['num_388', 'num_262', 'num_277', 'num_609', 'num_477', 'num_395']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfs_model.features_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f44bfa68-44ca-41a0-ada0-d0ccc6f9f0a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfs_model.base_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e61759ed-9b48-437b-aea9-a834a4634e87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72\n"
     ]
    }
   ],
   "source": [
    "y_pred = sfs_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e19130c7-25ab-4dca-951c-ed9ce57b8ecd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train.drop(sfs_model.features_to_drop, axis = 1), y_train)\n",
    "y_pred = clf.predict(X_test.drop(sfs_model.features_to_drop, axis = 1))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simpml",
   "language": "python",
   "name": "simpml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
